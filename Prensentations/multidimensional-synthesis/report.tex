
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% I, the copyright holder of this work, release this work into the
%% public domain. This applies worldwide. In some countries this may
%% not be legally possible; if so: I grant anyone the right to use
%% this work for any purpose, without any conditions, unless such
%% conditions are required by law.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[compress]{beamer}
\usetheme[faculty=phil, navigation, microtype]{fibeamer}
%\usetheme[logo=resources/NOKIA]{fibeamer}
\useoutertheme{miniframes}
\setbeamercolor{section in head/foot}{fg=white, bg=fibeamer@blue}
\usepackage[francais]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\title{Requêtes probabilistes et pondérées en logique d'arbre de calcul %\includegraphics[width=0.25\linewidth]{fibeamer/logo/mu/storm}
\title{Synthèse multi-objectifs dans les processus décisionnels de Markov} %% that will be typeset on the
%\subtitle{Presentation Subtitle} %% title page.
\author{Florent Delgrange}
\vspace{0.5cm}
\subtitle{\normalsize UMONS \\ Faculté des Sciences \\ Mab2 Science Informatique}
\date{\today}
%% These additional packages are used within the document:
\usepackage{ragged2e}  % `\justifying` text
\usepackage{cancel}
\usepackage{bbold}
\usepackage{booktabs}  % Tables
\usepackage{slashed}
\usepackage{centernot}
\usepackage{tabularx}
\usepackage{tikz}      % Diagrams
\usetikzlibrary{calc, shapes, backgrounds}
\usepackage{arevtext,arevmath}
\usepackage{verbatim}
\usepackage{amsmath, amssymb}
\usepackage{url}       % `\url`s
\usepackage{listings}
\usepackage{changepage}
\usepackage{cprotect}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{minted}
\usepackage{biblatex}
\usepackage{mathtools}
\usepackage{multicol}
\usepackage{bbold}
\frenchspacing

\input{prism}

\definecolor{DarkOrange}{HTML}{FF8C00}
\theoremstyle{theorem}%{3pt}{3pt}{\slshape}{}{\bfseries}{.}{.5em}{}
\newtheorem{theoreme}{Théorème}
\newtheorem{lemme}{Lemme}

\bibliography{bib}
\begin{document}
  \begin{frame}[plain]
    \maketitle
  \end{frame}

  \AtBeginSection[]
    {
      %  \begin{frame}<beamer>
      %  \frametitle{Plan}
      %  \tableofcontents[currentsection]
      %  \end{frame}
      \begin{frame}{\contentsname}
      \vspace{-0.05\linewidth}
      %\footnotesize
      \begin{multicols}{2}
      \tableofcontents[currentsection]
      \end{multicols}
      \end{frame}
    }

\section{SP-G}
\subsection{Motivations}
\begin{frame}{Borne supérieure stricte dans un MDP}
  Soit $\mathcal{M} = (S, A, \Delta, w)$, un MDP, $s \in S$, un état de $\mathcal{M}$ et $T \subseteq S$, un sous-ensemble d'états cibles.\\ On va définir une stratégie $\sigma$ qui
    \textbf{\color{fibeamer@orange}garantit d'atteindre $T$ depuis $s$ avec un coût inférieur à un seuil $l$:}
    \begin{itemize}
      \item[$\leadsto$] $\forall \pi \in Paths^\sigma(s), \; TS^T(\pi) \leq l$
      \item[$\equiv$] $\mathbb{P}_s^\sigma (\Diamond_{\leq l} T ) = 1$
    \end{itemize}
%   \item minimise l'espérance du coût de l'accessibilité à $T$ tout en ayant une garantie de ne pas dépasser un seuil de coût $l$.
%     \begin{align*}
%       & \min_\sigma \quad \mathbb{E}_s^\sigma(\Diamond T) & \text{tel que} && \mathbb{P}_s^\sigma(\Diamond_{\leq l} T) = 1&
%     \end{align*}
On veut donc assurer une \textbf{\color{fibeamer@orange}borne supérieure stricte}
lors de l'accessibilité à $T$.
\end{frame}

\begin{frame}{Borne supérieure stricte dans un MDP}{Remarque}
  \begin{itemize}
    \item $\forall \pi \in Paths^\sigma(s), \; TS^T(\pi) \leq l$
    \item $\mathbb{P}_s^\sigma (\Diamond_{\leq l} T ) = 1$ \\
  \end{itemize}
  {\small {\color{fibeamer@orange}$w:A \rightarrow \mathbb{N}_0$} $\implies$ Ces deux propositions sont équivalentes ! \\
  En effet, le problème \textit{SSP-P} induit un \textbf{\color{fibeamer@orange}dépliage} de $\mathcal{M}$, dont le graphe sous-jacent est un DAG (si on ne considère pas les les états terminaux).}
  \begin{center}
    \includegraphics[width=0.7\linewidth]{resources/unfolding}
  \end{center}
\end{frame}

\begin{frame}{Problème du plus court chemin dans un jeu}
    Assurer une borne supérieure stricte lors de l'accessibilité à $T$  \\ {\color{fibeamer@blue}$\leadsto$} Problème \textbf{\color{fibeamer@orange}SP-G} (\textit{Shortest path game problem}) \\
    \`A chaque étape,
    \begin{itemize}
      \item \textbf{Joueur 1} : choisit l'action par stratégie
      \item \textbf{Joueur 2} : choisit le successeur $s'$, i.e., l'état qui mène au pire cas en terme de somme tronquée
    \end{itemize}
\end{frame}

\subsection{Définition}
\begin{frame}{Problème du plus court chemin dans un jeu}
  \begin{definition}[SP-G]
    Soient $\mathcal{M} = (S, A, \Delta, w)$ un MDP, $s \in S$, un état de $\mathcal{M}$, $T \subseteq S$, un sous-ensemble d'états cibles et un seuil $l \in \mathbb{N}$. \\
    Le problème \textit{\color{fibeamer@orange}SP-G} consiste à décider s'il existe une stratégie $\sigma$ pour laquelle
    \[
      \forall \pi \in Paths^\sigma(s), \; TS^T(\pi) \leq l
    \]
    \[
      \equiv \quad \mathbb{P}_s^\sigma(\Diamond_{\leq l} T) = 1
    \]
  \end{definition}
  \begin{itemize}
    \item peut être décidé en temps polynomial
    \item stratégie sans mémoire
  \end{itemize}
\end{frame}

\subsection{Algorithme}
\begin{frame}{Problème du plus court chemin dans un jeu}{Hypothèses}
\[ w : A \rightarrow \mathbb{N}_0 \]
  \begin{itemize}
    \item Les coûts sont strictement positifs
    \item[$\leadsto$] La stratégie ne choisit pas d'action qui pourrait mener à un cycle pendant la minimisation de $TS^T$
    \begin{itemize}
      \item pas d'intérêt car poids strictement positifs
    \end{itemize}
    \item[$\leadsto$] \alert{$TS^T = \infty$ si les cycles ne peuvent pas être évités}
  \end{itemize}
\end{frame}

\begin{frame}{SP-G : Programmation dynamique}{Algorithme}
    %Soient $\mathcal{M} = (S, A, \Delta, w)$ un MDP, $s \in S$, un état de $\mathcal{M}$, $T \subseteq S$, un sous-ensemble d'états cibles et un seuil $l \in \mathbb{N}$.\\
    $\mathbb{C}(s, i)$ est le plus court chemin jusque $T$ depuis $s$, après $i$ étapes, $\forall 0 \leq i \leq n, \; n = |S|$ (pas de cycle).% \[ \]
    \\ $ $ \vspace{-0.03\linewidth}\\
      \textbf{\color{fibeamer@orange}Initialisation : }
      \begin{itemize}
        \item $\forall t \in T$, $\mathbb{C}(t, 0) = 0$
        \item $\forall s \in S \setminus T$, $\mathbb{C}(s, 0) = \infty$
      \end{itemize}
      Soit $k \in \mathbb{N}$ tel que $0 < k < n$. Supposons que $\mathbb{C}(s, k-1)$ a déjà été calculé pour tout $s \in S$.
        Alors, pour tout $s \in S$,

  \[
    \mathbb{C}(s, k) =
    \min \{
      \mathbb{C}(s, k-1), \,
        \min_{\alpha \in A(s)} \underbrace{\max_{s'\in Succ(s, \alpha)} w(\alpha) + \mathbb{C}(s', k-1)}_{\textit{l'adversaire choisit le pire successeur}}
    \}
  \]
\end{frame}

\begin{frame}{SP-G : Programmation dynamique}{Algorithme}
  \[
    \mathbb{C}(s, k) =
    \min \{
      \mathbb{C}(s, k-1), \,
        \min_{\alpha \in A(s)} \max_{s'\in Succ(s, \alpha)} w(\alpha) + \mathbb{C}(s', k-1)
    \}
  \]
  \begin{center}
    \includegraphics[width=0.6\linewidth]{resources/sp-g}
  \end{center}
\end{frame}

\begin{frame}{SP-G : Programmation dynamique}{Algorithme}
La stratégie $\sigma$ existe s'il est possible d'atteindre $T$ depuis $s_0$ avec une longueur
de chemin d'au plus $l$ :
\[
  \mathbb{C}(s_0, n) \leq l \iff \exists \sigma, \; \mathbb{P}_{s_0}^\sigma(\Diamond_{\leq l} T) = 1
\]
\begin{center}
  \includegraphics[width=0.4\linewidth]{resources/sp-g2}
\end{center}
\end{frame}

\begin{frame}{SP-G : Programmation dynamique}{Algorithme}
  \textbf{\color{fibeamer@orange}Résumé :}
  \begin{itemize}
    \item $\mathbb{C}(s, k)$ correspond au plus court chemin de $s \in S$ à $T$ après \alert{au plus} $k$ étapes, i.e., après avoir traversé \alert{au plus} $k$ états.
    \item \`A chaque étape, le plus court chemin résulte du choix des actions minimisant, à chaque étape, le coût de la transition menant au \textit{pire} successeur (i.e., celui dont le chemin pour atteindre $T$ est le plus long) est choisit.
    \item Cycle depuis un état $\implies$ on ne peut pas atteindre $T$
    { \color{fibeamer@blue}
    \item $\forall k \in \mathbb{N}, \; \mathbb{C}(s, k-1) \geq \mathbb{C}(s, k)\quad$ pour tout $s \in S$
    %\item Dans le pire cas, le plus court chemin de $s$ à $T$ est celui où tous
    %  les états sont traversés.
    \item $\mathbb{C}(s, n) = \min_k \mathbb{C}(s, k)\quad$ pour tout $s \in S$
    }
  \end{itemize}
\end{frame}

\begin{frame}{SP-G}{Construction de la stratégie}
Soit $s \in S$. Par le fait que
\begin{itemize}
    \item $\forall k \in \mathbb{N}, \; \mathbb{C}(s, k-1) \geq \mathbb{C}(s, k)\quad$ pour tout $s \in S$
    %\item Dans le pire cas, le plus court chemin de $s$ à $T$ est celui où tous
    %  les états sont traversés.
    \item $\mathbb{C}(s, n) = \min_k \mathbb{C}(s, k)\quad$ pour tout $s \in S$
\end{itemize}
On peut construire une stratégie sans mémoire en se basant sur les résultats de $\mathbb{C}(s, n)$ de chaque $s \in S$:
\[
  \sigma : S \rightarrow A, \; s \mapsto arg \min_{\alpha \in A(s)} \max_{s' \in Succ(s, \alpha)} w(\alpha) + \mathbb{C}(s', n)
\]
\end{frame}

\begin{frame}{SP-G}{Construction de la stratégie : intuition}
\small
%\textbf{\color{fibeamer@orange}Idée} : Si $\mathbb{C}(s, n) \neq \infty$, alors
%il existe forcément un état pour lequel passe tel que $\mathbb{C}(s', n) - w(\alpha) = \mathbb{C}(s, n)$

% \begin{itemize}
%     \item $\forall k \in \mathbb{N}, \; \mathbb{C}(s, k-1) \geq \mathbb{C}(s, k)\quad$ pour tout $s \in S$
%     %\item Dans le pire cas, le plus court chemin de $s$ à $T$ est celui où tous
%     %  les états sont traversés.
%     \item $\mathbb{C}(s, n) = \min_k \mathbb{C}(s, k)\quad$ pour tout $s \in S$
% \end{itemize}
Soient $k \in \mathbb{N}, \; s \in S \setminus T$. Supposons que $\mathbb{C}(s, n) \neq \infty$.
\begin{center}
  \includegraphics[width=0.5\linewidth]{resources/sp-proof}
\end{center}
\begin{itemize}
  \item $\exists k \leq n$ tel que
$ \mathbb{C}(s, n) = \mathbb{C}(s, k) < \mathbb{C}(s, k-i) \quad \forall i \in \{0, \dots, k\}$ \\
  $\leadsto \; s$ atteint $T$ en $k$ étapes.
  \item $\exists s' \in Succ(s)$ et $\exists \alpha \in A(s)$ tels que $\mathbb{C}(s, k) = \mathbb{C}(s', k-1) + w(\alpha) = \mathbb{C}(s', n) + w(\alpha)$\\
  $\leadsto \; s$ accède à $T$ via $s'$, qui atteint $T$ en $k-1$ étapes.
\end{itemize}

\end{frame}

\begin{frame}{SP-G}{Note}
  \begin{itemize}
    \item poids négatifs : \alert{possible de résoudre en temps pseudo-polynomial}
    \item multi-dimensionnel + poids négatifs : \alert{indécidable}
  \end{itemize}
\end{frame}

\subsection{Exemple}
\begin{frame}{Exemple}{Communication entre noeuds dans un réseau de capteurs}
  \begin{center}
    \includegraphics[width=0.65\linewidth]{resources/example2.pdf}
  \end{center}
\end{frame}

\begin{frame}{Exemple}{Communication entre noeuds dans un réseau de capteurs}
      \begin{itemize}
        \item Un mur sépare $n_0$ et $n_2$
        \item Communication directe $n_0 \rightarrow n_2$
        \begin{itemize}
          \item[$\leadsto$] plus rapide que de passer par un noeud intermédiaire
          \item[$\leadsto$] nécessite plus d'énergie
          \item[$\leadsto$] risque de corruption des paquets envoyés (bruit)
        \end{itemize}
        \item Communication indirecte : $n_0 \rightarrow n_1 \rightarrow n_2$
        \begin{itemize}
          \item[$\leadsto$] plus lent ($n_1$ doit attendre la confirmation de réception du paquet par $n_2$ et $n_0$ doit attendre la confirmation de $n_1$)
          \item[$\leadsto$] consommation d'énergie normale
          \item[$\leadsto$] risque de perte de paquet négligeable
        \end{itemize}
      \end{itemize}
\end{frame}

\begin{frame}{Exemple}{Communication entre noeuds dans un réseau de capteurs}
  \begin{center}
    \only<1>{\includegraphics[width=0.7\linewidth]{resources/main-mdp}}
    \only<2>{\includegraphics[width=0.7\linewidth]{resources/main-mdp3}}
  \end{center}
\end{frame}

\begin{frame}{Exemple}{Communication entre noeuds dans un réseau de capteurs}
\textbf{Dutty cycle : }$12 ms \; \leadsto \; \exists \sigma, \; \mathbb{P}^\sigma_{s_0}(\Diamond_{\leq 12} \text{ sommeil}) = 1$ ?
\begin{columns}
  \begin{column}{0.5\linewidth}
    \includegraphics[width=\linewidth]{resources/main-mdp3}
  \end{column}
  \begin{column}{0.5\linewidth}
    \scriptsize
    \begin{itemize}
      \item[$k=0$] \begin{itemize}
        \item $\mathbb{C}(s_0, 0) = \mathbb{C}(s_1, 0) = \mathbb{C}(s_2, 0) = \infty$
        \item $\mathbb{C}(s_3, 0) = 0$
      \end{itemize}
      \item[$k=1$]
        \begin{itemize}
          \item $\mathbb{C}(s_0, 1) = \infty$
          \item $\mathbb{C}(s_1, 1) = 6 + 0 = 6$
          \item $\mathbb{C}(s_2, 1) = 2 + \infty = \infty$
        \end{itemize}
      \item[$k=2$]
        \begin{itemize}
          \item $\mathbb{C}(s_0, 2) = 2 + 6 = 8$
        \end{itemize}
      \item[$k=3$]
        \begin{itemize}
          \item $\mathbb{C}(s_2, 3) = 2 + 8 = 10$
        \end{itemize}
    \end{itemize}
  \end{column}
\end{columns}
\end{frame}

\section{SSP-WE}
\subsection{Motivations}
\begin{frame}{Au delà du pire cas...}
  \begin{itemize}
    \item On souhaite assurer simultanément un {\color{fibeamer@orange}seuil de pire cas} et une {\color{fibeamer@orange}bonne espérance}
  \end{itemize}
  \begin{columns}
    \begin{column}{0.5\linewidth}
      \includegraphics[width=\linewidth]{resources/main-mdp}
    \end{column}
    \begin{column}{0.5\linewidth}
      Quelle est l'espérence optimale du temps d'envoi d'informations au senseur $n_2$ qui assure de respecter le \textit{dutty cycle} du senseur $n_0$ ($12 ms$)  ?
    \end{column}
  \end{columns}
\end{frame}

\subsection{Définition}
\begin{frame}{Espérance sous un pire cas}
  \small
  \begin{definition}[SSP-WE]
    Soient $\mathcal{M}=(S, A, \Delta, w)$, un MDP à une dimension (i.e., tel que $w : A \rightarrow \mathbb{N}_0$), un état initial $s \in S$, un sous-ensemble d'états cibles $T \subseteq S$ et deux seuils $l_1, l_2 \in \mathbb{N}$.
    Le problème consiste à décider s'il existe une stratégie $\sigma$ pour laquelle
    \begin{itemize}
      \item $\forall \pi \in Paths^\sigma(s), \; TS^T(\pi) \leq l_1 \quad
        \equiv \quad \mathbb{P}^\sigma_s(\Diamond_{\leq l_1} T) = 1$
      \item $\mathbb{E}_s^\sigma(\Diamond T) \leq l_2$
    \end{itemize}
  \end{definition}
  \begin{itemize}
    \item décidé en temps {\color{fibeamer@orange}pseudo-polynomial}
    \item NP-hard
    \item mémoire pseudo-polynomiale lors de la construction de la stratégie
  \end{itemize}
\end{frame}

\subsection{Algorithme}
\begin{frame}{SSP-WE}{Algorithme}
  \begin{enumerate}
    \item Construire $\mathcal{M}_{l_1}$, le MDP $\mathcal{M}$ déplié jusque $l_1$
    \item Calculer, $\mathbb{A}$, l'ensemble des actions possibles de l'\textit{\color{fibeamer@orange}attracteur} de $T' = \{ (t, v) \in S_{l_1} \; | \; t \in T \text{ et } v \leq l_1\}$
    \begin{itemize}
      \item[$\leadsto$] pour chaque état $(s, v) \in S_{l_1}$, $\mathbb{A}(s, v)$ est l'ensemble des actions $\alpha \in A(s)$ qui assurent à $(s, v)$ d'atteindre $T'$ dans $\mathcal{M}_{l_1}$, quelle que soit l'issue de l'évolution du système \textit{par l'adversaire} (i.e., l'incertitude lié aux probabilités).
    \end{itemize}
    \item Construire $\mathcal{M}^{\mathbb{A}}_{l_1}$, le MDP déplié limité à l'attracteur de $T'$
    \begin{itemize}
      \item[$\leadsto$] on supprime les états $(s, v)$ de $\mathcal{M}_{l_1}$ tels que $\mathbb{A}(s, v) = \emptyset$
    \end{itemize}
    \item Résoudre le problème SSP-E sur $\mathcal{M}_{l_1}^\mathbb{A}$
  \end{enumerate}
\end{frame}

\begin{frame}{SSP-WE}{Algorithme}
\footnotesize
$\mathbb{A}(s, v)$ peut être calculé récursivement :
\begin{itemize}
  \item \textbf{\color{fibeamer@orange}Idée} : $\mathbb{A}_i(s, v)$ correspond à l'ensemble des actions garantissant au système d'évoluer vers un état sûr (i.e., non-terminal) après $i$ étapes.
  \item $\mathbb{A}_0(s, v) = A(s) \quad $ si $v \leq l$ \\
        $\mathbb{A}_0(s, v) = \emptyset \quad \quad \;$ si $v = \bot$
  \item Soit $i \in \mathbb{N}$. On suppose que $\mathbb{A}_i(s, v)$ a été
    calculé pour tout $(s, v) \in S_{l_1}$. Alors,
\end{itemize}
{
    \[
      \mathbb{A}_{i+1}(s, v) = \{ \alpha \in \mathbb{A}_i(s, v) \; | \;
        \forall (s', v') \in Succ( (s, v), \alpha ), \; \mathbb{A}_i(s', v') \neq \emptyset \}
    \]
}
\begin{center}
  \includegraphics[width=0.5\linewidth]{resources/attractor}
\end{center}
\end{frame}

\begin{frame}{SSP-WE}{Algorithme}
  \begin{itemize}
    \item La taille de l'ensemble $\mathbb{A}_i$ est croissante en $i$, i.e., \\
      $|\mathbb{A}_{i}| \geq |\mathbb{A}_{i+1}| \quad \forall i \in \mathbb{N}$ par construction de $\mathbb{A}$
    \item Le dépliage du MDP résulte en un DAG
    \begin{itemize}
      \item[$\implies$] pas de cycle !
      \item[$\implies$] le nombre d'itérations $i$ est donc borné par $v$ (= pire cas $\rightarrow$ toutes les actions ont un coût de 1)
      \item[$\implies$] le temps de construction de $\mathbb{A}$ est donc polynomial en la taille du MDP déplié $\mathcal{M}_{l_1} \leadsto \mathcal{O}(v \, \times \, |S_{l_1}|)$
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{SSP-WE}{Construction de la stratégie}
  $\sigma$ est la stratégie à mémoire finie résultante de la résolution du problème SSP-E sur le MDP $\mathcal{M}_{l_1}^\mathbb{A}$ ($\sigma$ est sans mémoire sur $\mathcal{M}_{l_1}^\mathbb{A}$).
  \begin{itemize}
    \item[$\leadsto$] complexité pseudo-polynomiale
    \item[$\leadsto$] NP-difficile (pas de temps polynomial à moins que P = NP)
  \end{itemize}
\end{frame}

\subsection{Exemple}
\begin{frame}{SSP-WE}{Exemple}
    \[ \overset{?}{\exists} \sigma \; \mathbb{E}^{\sigma}_{s_0}(\Diamond \text{ sommeil}) \leq l \wedge \mathbb{P}^\sigma_{s_0}(\Diamond_{\leq 12} \text{ sommeil}) = 1 \]
    {\footnotesize Avec $l$, l'espérance minimale pour laquelle le noeud $n_0$ est assuré d'envoyer les données au noeud $n_2$ en moins de $12 ms$ (afin d'assurer un \textit{dutty cycle de $12 ms$}).}
    \begin{center}
      \includegraphics[width=0.6\linewidth]{resources/main-mdp3}
    \end{center}
\end{frame}

\begin{frame}{SSP-WE}{Exemple}
    \[ \overset{?}{\exists} \sigma \; \mathbb{E}^{\sigma}_{s_0}(\Diamond\text{ sommeil}) \leq l \wedge \mathbb{P}^\sigma_{s_0}(\Diamond_{\leq 12} \text{ sommeil}) = 1 \]
      \only<1>{\includegraphics[width=\linewidth]{resources/example-unfolding}}
      \only<2>{
        \includegraphics[width=\linewidth]{resources/example-unfoldingA}
      }
\end{frame}

\begin{frame}{SSP-WE}{Exemple}
    \only<1>{\[ \leadsto \mathbb{E}^{\min}_{s_0, 0}(\Diamond \{ (s_3, v) \; | \; v \leq 12\}) = ? \]}
    \only<2>{\vspace{-0.02\linewidth}
    \[ \leadsto \mathbb{E}^{\min}_s(\Diamond \{ (s_3, v) \; | \; v \leq 12\}) = \frac{7}{8} \cdot 4 + \frac{1}{8} \cdot 12 = 5 \]}
    \only<1>{\includegraphics[width=0.95\linewidth]{resources/example-unfoldingA2}}
    \only<2>{\includegraphics[width=0.95\linewidth]{resources/example-unfoldingA3}}
\end{frame}

\begin{frame}{SSP-WE}{Exemple}
    \vspace{-0.05\linewidth}
    \[ \mathbb{E}^{\sigma}_{s_0}(\Diamond \text{ sommeil}) \leq 5 \wedge \mathbb{P}^\sigma_{s_0}(\Diamond_{\leq 12} \text{ sommeil}) = 1 \]
    \begin{center}
      \includegraphics[width=0.6\linewidth]{resources/main-mdp3}
    \end{center}
    \vspace{-0.05\linewidth}
    \begin{itemize}
      \item \textbf{\color{fibeamer@orange}Stratégie optimale $\sigma$} : tester une fois un envoi direct et passer par le noeud $n_1$ si l'envoi direct est un échec.
    \end{itemize}
\end{frame}

\begin{frame}{SSP-WE}{Exemple dans Storm}
  \scriptsize
  \begin{columns}
    \begin{column}{0.5\linewidth}
  \lstinputlisting[language={Prism},
      numbers=left,
      rulesepcolor=\color{black}, rulecolor=\color{black}, breaklines=true,
      breakatwhitespace=true, firstnumber=1, firstline=1, lastline=25]{resources/sensors.prism}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{center}
        \includegraphics[width=\linewidth]{resources/main-mdp3}
      \end{center}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{SSP-WE}{Exemple dans Storm}
    \vspace{-0.05\linewidth}
    \footnotesize
    \begin{align*}
      &\overset{?}{\exists} \sigma \; \mathbb{E}^{\sigma}_{s_0}(\Diamond \text{ sommeil}) \leq 5 \wedge \mathbb{P}^\sigma_{s_0}(\Diamond_{\leq 12} \text{ sommeil}) = 1 \\
      \equiv_{\text{\tiny PRCTL}}s_0 &\overset{?}{\models} multi\big( \mathcal{E}^{\min}_{\leq 5} (\Diamond \text{ sommeil}), \; \mathcal{P}^{\max}_{=1} (\Diamond_{\leq 12} \text{ sommeil})\big)
    \end{align*}
     {\fontsize{4}{5}
  \begin{verbatim}
storm --prism resources/sensors.prism --prop "multi(Rmin<=5 [F \"sleep\"], Pmax>=1 [F{\"time\"}<=12 \"sleep\"])"
Storm 1.2.0

Command line arguments: --prism resources/sensors.prism --prop multi(Rmin<=5 [F "sleep"], Pmax>=1 [F{"time"}<=12 "sleep"])

Time for model construction: 0.305s.

--------------------------------------------------------------
Model type: 	MDP (sparse)
States: 	4
Transitions: 	6
Choices: 	5
Reward Models:  time
State Labels: 	3 labels
   * deadlock -> 0 item(s)
   * init -> 1 item(s)
   * sleep -> 1 item(s)
Choice Labels: 	none
--------------------------------------------------------------

Model checking property multi(R[exp]min<=5 [F "sleep"], Pmax>=1 [true Urew{"time"}<=12 "sleep"]) ...
Result (for initial states): true
Time for model checking: 0.038s.
  \end{verbatim}
  }
\end{frame}

\begin{frame}[fragile]{SSP-WE}{Exemple dans Storm (requête)}
    \vspace{-0.05\linewidth}
    \footnotesize
    \begin{align*}
    &\min_{\sigma \; | \;  \mathbb{P}^\sigma_{s_0}(\Diamond_{\leq 12} \text{ sommeil}) = 1} \, \mathbb{E}^{\sigma}_{s_0}(\Diamond \text{ sommeil}) \\
      \equiv_{\text{\tiny PRCTL}}s_0 & \models multi\big( \mathcal{E}^{\min}_{=?} (\Diamond \text{ sommeil}), \; \mathcal{P}^{\max}_{=1} (\Diamond_{\leq 12} \text{ sommeil})\big)
    \end{align*}
  {\fontsize{4}{5}
  \begin{verbatim}
storm --prism resources/sensors.prism --prop "multi(Rmin=? [F \"sleep\"], Pmax>=1 [F{\"time\"}<=12 \"sleep\"])"
Storm 1.2.0

Command line arguments: --prism resources/sensors.prism --prop multi(Rmin=? [F "sleep"], Pmax>=1 [F{"time"}<=12 "sleep"])

Time for model construction: 0.348s.

--------------------------------------------------------------
Model type: 	MDP (sparse)
States: 	4
Transitions: 	6
Choices: 	5
Reward Models:  time
State Labels: 	3 labels
   * deadlock -> 0 item(s)
   * init -> 1 item(s)
   * sleep -> 1 item(s)
Choice Labels: 	none
--------------------------------------------------------------

Model checking property multi(R[exp]min=? [F "sleep"], Pmax>=1 [true Urew{"time"}<=12 "sleep"]) ...
Result (for initial states): 5
Time for model checking: 0.035s.
  \end{verbatim}
  }
\end{frame}

\section{SSP-PQ}
\subsection{MDP multidimensionnels}
\begin{frame}{MDP multidimensionnels}
  \begin{definition}[MDP multidimensionnel]
    Un MDP à $d \in \mathbb{N}_0$ dimensions est un tuple $\mathcal{M} = (S, A, \Delta, w)$ tel que
    \begin{itemize}
      \item $S$, $A$, $\Delta$ sont définis de la même façon que pour un MDP classique
      \item $w : A \rightarrow \mathbb{N}_0^d$ est une fonction de coût, associant chaque action à un coût (strictment positif) par dimension du MDP.
    \end{itemize}
  \end{definition}
\end{frame}

\begin{frame}{MDP multidimensionnel}{Exemple}
    On ajoute le coût en énergie de l'envoi d'un message de $n_0$ à $n_2$
  \begin{center}
    \includegraphics[width=0.7\linewidth]{resources/mdpmdp}
  \end{center}
\end{frame}

\subsection{Motivations}
\begin{frame}{Requêtes percentiles dans les MDP multi-dimensionnels}
  \textbf{\color{fibeamer@orange}Motivation} :
  \begin{itemize}
    \item satisfaire plusieurs requêtes d'accessibilité limité par un coût dans
      un MDP multidimensionnel.
  \end{itemize}
  \begin{center}
    \begin{columns}
      \begin{column}{0.4\linewidth}
        \includegraphics[width=\linewidth]{resources/mdmdp2}
      \end{column}
      \begin{column}{0.6\linewidth}{\small
        \begin{itemize}
          \item $Q_1 := \mathbb{P}^{\sigma_1}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) \geq 0.8$
          \item $Q_2 := \mathbb{P}^{\sigma_2}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \geq 0.9$
            \item[$\leadsto$] $\sigma_1 : $ envoi direct
            \begin{itemize}
              \item[$\implies$] \only<1>{$\mathbb{P}^{\sigma_1}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) = 0.875$}
              \only<2>{
                ne satisfait pas $Q_2$
              }
            \end{itemize}
            \item[$\leadsto$] $\sigma_2 : $ envoi par un noeud intermédiaire
            \begin{itemize}
              \item[$\implies$] \only<1>{$\mathbb{P}^{\sigma_2}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) = 1$}
              \only<2>{
                ne satisfait pas $Q_1$
              }
          \end{itemize}
        \end{itemize}
        }
      \end{column}
    \end{columns}
  \end{center}

\end{frame}

\begin{frame}{Requêtes percentiles dans les MDP multi-dimensionnels}
  \textbf{\color{fibeamer@orange}Motivation} :
  \begin{itemize}
    \item satisfaire plusieurs requêtes d'accessibilité limité par un coût dans
      un MDP multidimensionnel.
  \end{itemize}
  \begin{center}
    \begin{columns}
      \begin{column}{0.4\linewidth}
        \includegraphics[width=\linewidth]{resources/mdmdp2}
      \end{column}
      \begin{column}{0.6\linewidth}{\small
        \begin{itemize}
          \item $Q_1 := \mathbb{P}^{\sigma_1}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) \geq 0.8$
          \item $Q_2 := \mathbb{P}^{\sigma_2}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \geq 0.9$
        \end{itemize}
        }
      \end{column}
    \end{columns}
  \end{center}
  \begin{itemize}
    \item[$\leadsto$] Résoudre un tel problème requiert une \textit{\color{fibeamer@orange}stratégie à mémoire finie}
  \end{itemize}
\end{frame}

\begin{frame}{Requêtes percentiles dans les MDP multi-dimensionnels}
  \small
      $\sigma_{1 \wedge 2} := $ essayer une fois un envoi direct et passer ensuite par $n_1$ si l'envoi direct a échoué
      \begin{center}
        \includegraphics[width=0.7\linewidth]{resources/strategy}
      \end{center}
  \begin{center}
    \begin{columns}
      \begin{column}{0.4\linewidth}
        \includegraphics[width=\linewidth]{resources/mdmdp2}
      \end{column}
      \begin{column}{0.6\linewidth}{ \footnotesize
        \begin{itemize}
          \item $Q_1 := \mathbb{P}^{\sigma_{1 \wedge 2}}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) \geq 0.8$
          \item $Q_2 := \mathbb{P}^{\sigma_{1 \wedge 2}}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \geq 0.9$
          \item $\mathbb{P}^{\sigma_{1 \wedge 2}}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) = 0.875 \models Q_1$
          \item $\mathbb{P}^{\sigma_{1 \wedge 2}}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) = 1 \models Q_2 $
          \begin{itemize}
            \scriptsize
            \item[$\leadsto$] $394 \leq TS^{\{s_3\}}(\pi) \leq 690$ $\forall \pi \in Paths^{\sigma_{1 \wedge 2}}(s_0)$
          \end{itemize}
        \end{itemize}
        }
      \end{column}
      \end{columns}
      \end{center}
\end{frame}


\subsection{Définition}
\begin{frame}{SSP-PQ}
  \footnotesize
% \begin{definition}[SSP-PQ]
%   Soient $\mathcal{M} = (S, A, \Delta, w)$, un MDP multidimensionnel tel que
%   $w: A \rightarrow \mathbb{N}_0^d$, $s \in S$, un état de $\mathcal{M}$ et $q \in \mathbb{N}$
%   contraintes percentiles. \\
%   Ces contraintes percentiles sont décrites par les ensembles d'états cibles
%   $T_i \subseteq S$, les dimensions $k_i \in \{1, \dots, d\}$, les seuils
%   de longueur $l_i \in \mathbb{N}$ et les seuils de probabilité $\alpha_i \in
%   [0, 1] \cap \mathbb{Q}$, pour tout $i \in \{1, \dots, q\}$. \\
%   Le problème \textit{\color{fibeamer@orange}SSP-PQ} consiste à décider s'il existe une stratégie $\sigma$ pour laquelle la propriété
%   \[
%     \bigwedge_{i \in \{1, \dots, q\}} \mathbb{P}_s^\sigma(\Diamond_{k_i\, : \, \leq l_i} T_i) \geq \alpha_i
%   \]
%   où $\Diamond{k_i:\leq l_i}T_i$ dénote l'ensemble des chemins satisfaisant $\Diamond_{\leq l_i} T_i$ sur la dimensions $k_i$
% \end{definition}
  \begin{definition}[SSP-PQ]
    Soient {\color{fibeamer@orange}$\mathcal{M} = (S, A, \Delta, w)$}, un MDP multidimensionnel tel que
    {\color{fibeamer@orange}$w: A \rightarrow \mathbb{N}_0^d$}, {\color{fibeamer@orange}$s \in S$}, un état de $\mathcal{M}$ et {\color{fibeamer@orange}$q \in \mathbb{N}$
    contraintes percentiles}. \\
    Ces contraintes percentiles sont décrites par les ensembles d'états cibles
    {\color{fibeamer@orange}$T_i \subseteq S$}, les {\color{fibeamer@orange}dimensions $k_i \in \{1, \dots, d\}$}, les seuils
    de longueur {\color{fibeamer@orange}$l_i \in \mathbb{N}$} et les seuils de probabilité {\color{fibeamer@orange}$\alpha_i \in
    [0, 1] \cap \mathbb{Q}$}, pour tout $i \in \{1, \dots, q\}$. \\
    Le problème \textit{\color{fibeamer@orange}SSP-PQ} consiste à décider s'il existe une stratégie {\color{fibeamer@orange}$\sigma$} pour laquelle la requête suivante est satisfaite : {\color{fibeamer@orange}
    \[
      \mathcal{Q} := \bigwedge_{i \in \{1, \dots, q\}} \mathbb{P}_s^\sigma(\Diamond_{k_i\, : \, \leq l_i} T_i) \geq \alpha_i
    \]}
    où $\Diamond_{k_i:\leq l_i}T_i$ dénote l'ensemble des chemins satisfaisant $\Diamond_{\leq l_i} T_i$ sur la dimension $k_i$
  \end{definition}
  \begin{itemize}
    \item peut être décidé en \alert{temps exponentiel}
    \item \alert{PSPACE-difficile}
  \end{itemize}
\end{frame}

\subsection{Algorithme}
\begin{frame}{SSP-PQ}{Algorithme}
  \begin{enumerate}
    \item Construire $\mathcal{M}_l$, le MDP déplié de $\mathcal{M}$, de la même
      façon que pour le problème SSP-P, mais tel que $l = \max_i l_i$.
      \begin{itemize}
        \item $S_{l} \in S \times (\{ 0, \dots, l \} \cup \{ \bot \})^d$
        \item un chemin n'est écarté que lorsque le coût du chemin courant, pour chacune de ses dimensions $j$, excède $\max_i l_i$,\\ { \footnotesize avec
          $i \in \{ 1, \dots, q \; | \; \mathcal{Q}_i := \mathbb{P}_s^\sigma(\Diamond_{k_i\, : \, \leq l_i} T_i) \geq \alpha_i \, \wedge \, k_i = j \}$}
        \item certains chemins peuvent dépasser le seuil de longueur d'une requête
        tout en restant intéressants pour la stratégie
        \item en effet, on ne cherche pas forcément à atteindre un état qui satisfait toutes les contraintes de coûts à la fois !
        \item[$\leadsto$] notion de \textbf{\color{fibeamer@orange}compromis}
      \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}{SSP-PQ}{Algorithme}
  \begin{enumerate}
    \small
    \item Construire $\mathcal{M}_l$, le MDP déplié de $\mathcal{M}$, de la même
      façon que pour le problème SSP-P, mais tel que $l = \max_i l_i$.
    \item Pour chaque requête $i \in \{1, \dots, q\}$, on calcule un ensemble
      d'états cibles $R_i$ dans $M_l$ pour lequel tous les états contenus dans
      cet ensemble satisfont la contrainte liée au coût de cette requête.
    \item Résoudre le \textit{\color{fibeamer@orange}problème d'accessibilité \textbf{multiple}} aux différent ensembles $R_i$, pour chaque requête $i \in \{1, \dots, q\}$.
    On recherche donc une stratégie $\sigma_l$ qui assure au système d'atteindre les ensembles $R_i$ depuis $(s, 0, \dots, 0)$ avec une probabilité $\alpha_i$
    \begin{itemize}
      \item[$\leadsto$] peut être répondu en temps \alert{polynomial en $|\mathcal{M}_{l}|$} ...
      \item[$\leadsto$] ... mais \alert{exponentiel en $|R_i|$, i.e., $q$}
    \end{itemize}
  \end{enumerate}
\end{frame}

\begin{frame}{SSP-PQ}{Algorithme : exemple}
    \begin{columns}
      \begin{column}{0.3\linewidth}
        \includegraphics[width=\linewidth]{resources/mdmdp2}
      \end{column}
      \begin{column}{0.7\linewidth}{\small
        \begin{itemize}
          \item $Q_1 := \mathbb{P}^{\color{red}\sigma}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) \geq 0.8$
          \item $Q_2 := \mathbb{P}^{\color{red}\sigma}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \geq 0.9$
        \end{itemize}
        }
      \end{column}
    \end{columns}
  \vspace{0.04\linewidth}
  {\small \textbf{\color{fibeamer@orange}Idée clé : } il est nécessaire qu'il y ait une possibilité pour que les labels {\color{DarkOrange}$q_1$} \textbf{et} {\color{DarkOrange}$q_2$} apparaissent au moins une fois dans le futur dans $\mathcal{M}^{\color{red}\sigma}$}
  \vspace{-0.02\linewidth}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/SSP-PQ-unfolding}
  \end{center}
\end{frame}

\begin{frame}{SSP-PQ : stratégies}
\footnotesize
\begin{definition}[Stratégie aléatoire]
Une stratégie aléatoire sans mémoire est une stratégie $\sigma$ telle que
\[
  \sigma : S \rightarrow \mathcal{D}(A)
\]
où $\mathcal{D}$ est une distribution de probabilité sur $A$.
Les stratégies aléatoires à mémoire sont définies d'une façon similaire.
\end{definition}

\begin{theoreme}
  Les stratégies qui résolvent le problème SSP-PQ ont besoin à la fois de mémoire (sans mémoire dans $\mathcal{M}_{l}$) et d'aléatoire (pour résoudre le problème d'accessibilité multiple  dans $\mathcal{M}_l$)
\end{theoreme}

\end{frame}

\begin{frame}{SSP-PQ : stratégies}
  \begin{itemize}
    \item La construction d'une stratégie requiert de résoudre le problème
    d'\textit{\color{fibeamer@orange}accessibilité multiple  G-SR} dans le MDP déplié jusque $l$, i.e., $\mathcal{M}_l$
    \item Le problème d'accessibilité multiple  est une généralisation du problème SR dans les MDP.
    \item Comment construire une telle stratégie ?
  \end{itemize}
\end{frame}

\section{G-SR}
\subsection{Définition}
\begin{frame}{Problème d'accessibilité multiple }
  \begin{definition}[G-SR]
  \small
    Soient {\color{fibeamer@orange}$\mathcal{M} = (S, A, \Delta)$}, un MDP, {\color{fibeamer@orange}$s \in S$}, un état de $\mathcal{M}$ et {\color{fibeamer@orange}$q \in \mathbb{N}$
    contraintes}. \\
    Ces contraintes sont décrites par les ensembles d'états cibles
    {\color{fibeamer@orange}$T_i \subseteq S$} et les seuils de probabilité {\color{fibeamer@orange}$\alpha_i \in
    [0, 1] \cap \mathbb{Q}$}, pour tout $i \in \{1, \dots, q\}$. \\
    Le problème \textit{\color{fibeamer@orange}G-SR} est une généralisation du problème SR qui consiste à décider s'il existe une stratégie {\color{fibeamer@orange}$\sigma$} pour laquelle la requête suivante est satisfaite : {\color{fibeamer@orange}
    \[
      \mathcal{Q} := \bigwedge_{i \in \{1, \dots, q\}} \mathbb{P}_s^\sigma(\Diamond T_i) \geq \alpha_i
    \]}
  \end{definition}
\end{frame}

\subsection{Préliminaires}
\begin{frame}{Nettoyer un MDP}
\footnotesize
  Soient $\mathcal{M} = (S, A, \Delta)$, un MDP et $q \in \mathbb{N}$ contraintes d'accessibilité. On défini l'ensemble $T$ comme étant l'ensemble des états cibles qui décrivent les $q$ contraintes, i.e., $T = \bigcup_{i \in \{1, \dots, q \}} T_i$. {\color{fibeamer@blue}Nettoyer $\mathcal{M}$ consiste à créer un nouveau MDP $\mathcal{M}_T = (S_T, A_T, \Delta_T)$ tel que}
  \begin{itemize}
    \item $A_T = A \cup \{\alpha_T, {\color{gray}\alpha_{dead}}\}$
    \item Les états de $T$ sont absorbants, i.e., $\forall t \in T, \,
      \Delta_T(t, \alpha_T, t) = 1$ et $A_T(t) = \{\alpha_T\}$
    \item $S_T = (S \setminus S_0) {\color{gray}\cup \{s_{dead}\}}$, avec
    $S_0 = \{ s \in S \; | \; \forall \sigma, \, \mathbb{P}^\sigma_s(\Diamond T) = 0 \}$
    \begin{itemize}
      \item {\scriptsize Pour chaque état $s \in S \setminus T$, on peut facilement vérifier si $\exists \sigma$ tel que
    $\mathbb{P}_s^\sigma (\Diamond T) > 0$ (si il existe un chemin de $s$ à $T$ dans le graphe sous-jacent de $\mathcal{M}$)}
    \end{itemize}
    \item[$\leadsto$] On a retiré les \textit{mauvais états de $S$}, i.e., on crée un état \alert{$s_{dead}$ invisible absorbant}
    \begin{itemize}{\scriptsize
      \item[$\implies$] $\forall s \in S, \, \sum_{\alpha \in A(s)} \Delta_T(s, \alpha, s') \leq 1$
      \item[$\leadsto$] \textbf{\color{fibeamer@orange}Transition invisible : }$\Delta_T(s, \alpha, s_{dead}) = 1 - \sum_{s' \in Succ(s, \alpha)} \Delta_T(s, \alpha, s')$
      }
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{Nettoyer un MDP}{Exemple}
  \includegraphics[width=\linewidth]{resources/clean-up}
\end{frame}

\begin{frame}{Courbe de Pareto}
  \small
  \begin{itemize}
    \item Ensemble des vecteurs $p$ de {\color{fibeamer@orange}points $p_1, \dots, p_q$ réalisables} qui satisfont les contraintes de probabilités $\alpha_i$, i.e., $p \geq \alpha$ {\color{fibeamer@orange}tel qu'il n'existe pas de vecteur $p'$ qui domine $p$}, i.e., tel que $\neg {\exists} p', \, p \leq p'$
    \item $U_\mathcal{Q} = \{ p \in [0, 1]^q \cap \mathbb{Q} \; | \; \exists \sigma, \, t^\sigma \geq p \; \wedge \; p \geq \alpha \}$, avec $t^\sigma = \mathbb{P}_s^\sigma(\Diamond T_i)$
    \begin{itemize}
      \item[$\leadsto$] Trop coûteux à calculer !
      \item[$\leadsto$] Notion de courbe de Pareto
    \end{itemize}
    \item $\mathcal{P} \subseteq U_\mathcal{Q}$, la \textit{\color{fibeamer@orange}courbe de Pareto de $U_\mathcal{Q}$}, contient tous les vecteurs $p$ \textit{\color{fibeamer@orange}Pareto optimaux} $\approx$ \textit{courbe des compromis}.
    \item $p \in U_\mathcal{Q}$ est Pareto-optimal ssi $\neg \exists p' (p'\in U_\mathcal{Q} \wedge p \leq p' \wedge p \neq p')$
    \item La courbe de Pareto est en général une surface polyhèdrale de taille superpolynomiale
  \end{itemize}
\end{frame}

\begin{frame}{Programme Linéaire multi-objectif}
\footnotesize
  On résout le problème G-SR via un \textit{\color{fibeamer@orange}programme linéaire à objectifs multiples}.
  \begin{itemize}
    \item Un programme linéaire à objectifs multiples (MOLP) se définit de la même façon qu'un LP classique à l'exception du fait qu'on cherche à satistfaire \alert{simultanément} plusieurs fonctions objectifs.
    \item Si les objectifs sont non-triviaux, \alert{il n'existe pas de solution unique qui optimise tous les objectifs simultanément}
    \begin{itemize}{ \scriptsize
      \item[$\leadsto$] compromis
      \item[$\leadsto$] pas de solution optimale
      }
    \end{itemize}
    \item Une solution acceptable d'un MOLP est une solution \textit{non-dominante}
    \begin{itemize} { \scriptsize
      \item[$\leadsto$] aucune fonction objectif ne peut être optimisée sans dégrader la valeur d'une autre fonction objectif.
      }
    \end{itemize}
    \item Soit $V$, l'ensemble des solutions qui satisfont toutes les
      contraintes du MOLP. L'ensemble des solutions acceptables du MOLP est la courbe de pareto $\mathcal{P} \subseteq V$
  \end{itemize}
\end{frame}

\begin{frame}{Courbe de Pareto}
  \begin{figure}
    \includegraphics[width=\linewidth]{resources/pareto}
    \caption{MDP avec deux objectifs, $\Diamond P_1$ et $\Diamond P_2$, ainsi que la courbe de Pareto associée \cite{KYV}}
  \end{figure}
\end{frame}

\subsection{MOLP}

\begin{frame}{G-SR}{Programme Linéaire multi-objectif}
  \footnotesize
  Supposons que le MDP est nettoyé. Le MOLP se définit comme suit : \\
    $\textbf{Objectifs } i \in \{ 1, \dots, q\} \; : \;
   \max \sum_{t \in T_i} y_t$ \\
    sous les contraintes
  \begin{flalign*}
    \sum_{s' \in Pred(t) \setminus T} \sum_{\alpha'\in A(s')} \Delta(s', \alpha', t) \cdot y_{s', \alpha'} &= y_t && \forall t \in T \\
     \mathbb{1}(s) +
      \sum_{s' \in Pred(s)} \sum_{\alpha' \in A(s')} \Delta(s', \alpha', s) \cdot y_{s', \alpha'} &= \sum_{\alpha \in A(s)} y_{s, \alpha} && \forall s \in S \setminus T \\
      y_t &\geq 0 && \forall t \in T_i \\
      y_{s, \alpha} &\geq 0 && \forall s \in S \setminus T \text{ et } \alpha \in A(s)
  \end{flalign*}
  \vspace{-0.05\linewidth}
  \begin{itemize}
    \item $\mathbb{1}(s) = 1$ ssi $s \in S$ est l'état pour lequel on cherche à satisfaire $\bigwedge_{i \in \{1, \dots, q\}} \mathbb{P}^\sigma_s(\Diamond T_i) \geq \alpha_i$
    \item Ce MOLP est dérivé du LP dual de celui du problème SR pour lequel la solution optimale est $x^*_s = \max_{\sigma} \mathbb{P}_s^\sigma(\Diamond T)$
  \end{itemize}
\end{frame}

\begin{frame}{G-SR}{MOLP}
    \small
    \vspace{-0.05\linewidth}
    \begin{equation*}
       \mathbb{1}(s) +
        \sum_{s' \in Pred(s)} \sum_{\alpha' \in A(s')} \Delta(s', \alpha', s) \cdot y_{s', \alpha'} = \sum_{\alpha \in A(s)} y_{s, \alpha} \quad \forall s \in S \setminus T
    \end{equation*}
    $y_{s, \alpha} = $ \textit{ espérance du nombre de fois
    que la transition $s\xrightarrow{\alpha}$ est empreintée} \\
    $\sum_{\alpha \in A(s)} y_{s, \alpha} = $ \textit{ espérance du nombre de fois que l'état $s$ est visité}
  \begin{center}
    \includegraphics[width=0.7\linewidth]{resources/MOLP2}
  \end{center}
\end{frame}

\begin{frame}{G-SR}{MOLP}
  \small
    \vspace{-0.05\linewidth}
    \begin{equation*}
      y_t = \sum_{s' \in Pred(t) \setminus T} \sum_{\alpha'\in A(s')} \Delta(s', \alpha', t) \cdot y_{s', \alpha'} \quad \forall t \in T
    \end{equation*}
    $y_t = $ \textit{espérance du nombre de fois qu'une transition atteint $t$ {\color{fibeamer@orange}pour la première fois}} \\
    $\leadsto$ il s'agit d'une autre façon de formuler la probabilité d'atteindre éventuellement $t$
  \begin{center}
    \includegraphics[width=0.7\linewidth]{resources/MOLP1}
  \end{center}
\end{frame}

\begin{frame}{G-SR}{MOLP}
\begin{center}
\[ \sum_{t \in T_i} y_t \]
correspond donc à la probabilité d'atteindre $T_i$ \\
{\color{fibeamer@blue}$\leadsto$} Si une solution acceptable du MOLP $y'$ existe, alors il reste à vérifier que
\[
  \sum_{t \in T_i} y'_t \geq \alpha_i \quad \forall i \in \{1, \dots, q\}
\]
\end{center}
\end{frame}

\begin{frame}{G-SR}
  \vspace{-0.05\linewidth}
  \begin{theoreme}
    \footnotesize
    Soient $\mathcal{M} = (S, A, \Delta)$, un MDP nettoyé, $s \in S$, un état de $\mathcal{M}$ et $q \in \mathbb{N}$
    contraintes décrites par les ensembles d'états cibles $T_i \subseteq S$ et
    les seuils de probabilités $\alpha_i \in [0, 1] \cap \mathbb{Q}$, pour tout $i \in \{1, \dots, q\}$. Les propositions suivantes sont équivalentes :
    \begin{enumerate}
      \item[$(1.)$] Il existe une stratégie aléatoire sans mémoire telle que
        \[
          \bigwedge_{i=1}^q \mathbb{P}_s^\sigma (\Diamond T_i) \geq \alpha_i
        \]
      \item[$(2.)$] Il existe une solution acceptable $y'$ au MOLP telle que
        \[
          \bigwedge_{i=1}^q \sum_{t \in T_i} y'_{t} \geq \alpha_i
        \]
    \end{enumerate}
  \end{theoreme}
\end{frame}

\subsection{Stratégie}
\begin{frame}{G-SR}{Construction de la stratégie}
\footnotesize
  Supposons que $y'$ est une solution acceptable du MOLP tel que
  \begin{equation}
    \sum_{t \in T_i} y'_t \geq \alpha_i > 0 \quad \forall i \in \{ 1, \dots, q \} \label{eqmolp}
  \end{equation}
  Soit $V = \{s \in S \setminus T \; | \; \sum_{\alpha \in A(s) y'_{s, \alpha}} y'_{s, \alpha} > 0\}$, les états par lesquels on passe afin de satisfaire (\ref{eqmolp}), alors
  $\forall s_v \in V$, $\alpha \in A(s_v)$
  \begin{align*}
    \sigma(s_v)(\alpha) &:= \frac{y'_{s_v, \alpha}}{\sum_{\alpha' \in A(s_v)} y'_{s_v, \alpha'}} \\
     &:= \frac{\mathbb{E}_s(\text{\# transition }s_v\xrightarrow{\alpha} \text{ est empreintée})}{\mathbb{E}_s(\text{\# visite de l'état }s_v)}
  \end{align*}
  \textit{Note : } Vu que $\sum_{\alpha \in A(s_v)} y'_{s_v, \alpha} > 0$, $\sigma(s_v)$ est une distribution de probabilité sur $A(s_v)$,i.e., $\mathcal{D}(A(s_v))$. Pour les autres états $s' \not \in V$, $\sigma(s')$ est une distribution de probabilité aléatoire sur $A(s')$, i.e., $\mathcal{D}(A(s'))$
\end{frame}

\begin{frame}{G-SR}{Stratégie et problème de flots}
  \small
  \begin{lemme}
    \centering
    La stratégie $\sigma$, construite de cette manière, satisfait $\bigwedge_{i=1}^q \mathbb{P}_s^\sigma (\Diamond T_i) \geq \alpha_i$
  \end{lemme}
  \textbf{\color{fibeamer@orange}Idée : } $y'$, une solution acceptable du MOLP, défini un \textbf{\color{fibeamer@orange}flot stochastique} dont la {\color{fibeamer@orange}source} est $s$ et dont les {\color{fibeamer@orange}puits} sont les états de $T$.
  \begin{itemize}
    \item Par conservation de flots, les états de $s \in S \setminus T$ qui ont un nombre de flots sortants positifs ($\#_{\alpha \in A(s)} s\xrightarrow{\alpha}$) $-$ et donc un nombre de flots entrants positifs
    \begin{itemize}
      \item doivent être tous accessibles depuis la source
      \item doivent tous atteindre $T$
      \item ne peuvent pas accéder aux états avec un flot nul
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{G-SR}{Stratégie et problème de flots}
  \begin{itemize}
    \item $\sigma$ est obtenue en normalisant les flots sortant de chaque action vers les états avec un nombre de flots sortants positif.
    \item En utilisant $\sigma$ définie de cette façon, l'espérance du nombre de fois que $\alpha \in A(s)$ est choisie alors que le système se trouve en l'état $s$ est donné par $y'_{s, \alpha}$.
    \item Par conséquent, vu que les transitions vers un état $t \in T$ depuis un état de $S \setminus T$ sont employées pour atteindre $t$ une \textbf{unique fois}, alors, les contraintes définissant $y'_t$ induisent $y'_t = \mathbb{P}_s^\sigma(\Diamond \{t\})$
  \end{itemize}
\end{frame}

\subsection{Exemple dans storm}
\begin{frame}{SSP-PQ et GSR}{Exemple dans Storm}
  \scriptsize
  \begin{columns}
    \begin{column}{0.5\linewidth}
  \lstinputlisting[language={Prism},
    	basicstyle=\fontsize{4}{5}\color{red}\ttfamily, % small true type font (like courier)
      numbers=left,
      rulesepcolor=\color{black}, rulecolor=\color{black}, breaklines=true,
      breakatwhitespace=true, firstnumber=1]{resources/sensors_pq.prism}
    \end{column}
    \begin{column}{0.5\linewidth}
      \begin{center}
        \includegraphics[width=\linewidth]{resources/mdmdp2}
      \end{center}
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{SSP-PQ et GSR}{Exemple dans Storm}
    \footnotesize
    \vspace{-0.05\linewidth}
    \begin{align*}
    &\overset{?}{\exists} \sigma, \; \mathbb{P}^{\sigma}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}) \geq 0.8 \, \wedge \,
              \mathbb{P}^{\sigma}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \geq 0.9 \\
      \equiv_{\text{\tiny PRCTL}}&s_0 \overset{?}{\models} multi\big( \mathcal{P}^{\max}_{\geq 0.8} (\Diamond_{1\, :\, \leq 4} \text{ sommeil}), \; \mathcal{P}^{\max}_{\geq 0.9} (\Diamond_{2\, :\, \leq 700} \text{ sommeil})\big)
    \end{align*}
  {\fontsize{4}{5}
  \begin{verbatim}
storm --prism ../../models/sensors.prism --prop "multi(Pmax>=0.8 [F{\"time\"}<=4 \"sleep\"], Pmax>=0.9 [F{\"energy\"}<=700 \"sleep\"])"
Storm 1.2.0

Command line arguments: --prism ../../models/sensors.prism
                        --prop multi(Pmax>=0.8 [F{"time"}<=4 "sleep"], Pmax>=0.9 [F{"energy"}<=700 "sleep"])

Time for model construction: 0.302s.

--------------------------------------------------------------

Model checking property multi(Pmax>=4/5 [true Urew{"time"}<=4 "sleep"], Pmax>=9/10 [true Urew{"energy"}<=700 "sleep"]) ...
Result (for initial states): true

Time for model checking: 0.003s.
  \end{verbatim}
  }
\end{frame}

\begin{frame}[fragile]{SSP-PQ et GSR}{Exemple dans Storm}
    \vspace{-0.05\linewidth}
    \footnotesize
    \begin{align*}
    &\max_\sigma \big(\mathbb{P}^{\sigma}_{s_0}(\Diamond_{1\, :\, \leq 4} \text{ sommeil}), \;
              \mathbb{P}^{\sigma}_{s_0}(\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \big) \\
      \equiv_{\text{\tiny PRCTL}}s_0 {\models} &multi\big( \mathcal{P}^{\max}_{=?} (\Diamond_{1\, :\, \leq 4} \text{ sommeil}), \; \mathcal{P}^{\max}_{=?} (\Diamond_{2\, :\, \leq 700} \text{ sommeil}) \big)
    \end{align*}
  {\fontsize{4}{5}
  \begin{verbatim}
storm --prism ../../models/sensors.prism --prop "multi(Pmax=? [F{\"time\"}<=4 \"sleep\"], Pmax=? [F{\"energy\"}<=700 \"sleep\"])"
Storm 1.2.0

Command line arguments: --prism ../../models/sensors.prism
                        --prop multi(Pmax=? [F{"time"}<=4 "sleep"], Pmax=? [F{"energy"}<=700 "sleep"])

Time for model construction: 0.452s.

Model checking property multi(Pmax=? [true Urew{"time"}<=4 "sleep"], Pmax=? [true Urew{"energy"}<=700 "sleep"]) ...
Result (for initial states):
Underapproximation of achievable values: Polytope with 2 Halfspaces:
   (         1,          0) * x <= 0.875
   (         0,          1) * x <= 1

Overapproximation of achievable values: Polytope with 2 Halfspaces:
   (         1,          0) * x <= 0.875
   (         0,          1) * x <= 1

1 pareto optimal points found
(Note that these points are safe, i.e., contained in the underapproximation, but there is no guarantee for optimality):
   (     0.875,          1 )


Time for model checking: 0.040s.
  \end{verbatim}
  }
\end{frame}


% \begin{frame}{G-SR}
%   \begin{block}{Proposition}
%     Soient $\mathcal{M} = (S, A, \Delta)$, un MDP nettoyé et $q \in \mathbb{N}$
%     contraintes de probabilité. Il existe une stratégie sans mémoire $\sigma$ aléatoire telle que $\bigwedge_{i=1}^q \mathbb{P}_s^\sigma (\Diamond T_i) \geq \alpha_i$ ssi
%     il existe une stratégie $\sigma'$ telle que \[\bigwedge_{i=1}^q \mathbb{P}_s^{\sigma'}(\Diamond T_i) \geq \alpha_i \wedge
%     \mathbb{P}_s^{\sigma'}(\Diamond T) > 0\] avec $T = \bigcup_i T_i$
%   \end{block}
%   Cela vient du fait que le MDP est nettoyé. Il est donc toujours possible d'accéder à $T$.
% \end{frame}

\subsection{}
\begin{frame}[allowframebreaks]
        \nocite{*}
        \frametitle{Références}
      \printbibliography
\end{frame}

\end{document}
