\chapter*{Appendix}
\addcontentsline{toc}{chapter}{Appendix}
\markboth{Appendix}{Appendix}
\renewcommand{\thechapter}{\Alph{chapter}}
\stepcounter{chapter}
\setcounter{chapter}{1}

\section{Systems of linear equations}
\subsection{Reachability in a Markov Chain}\label{app-reach}
Let $\mathcal{M} = (S, \Delta, w, AP, L)$ be an MC, $s \in S$ be a state of $\mathcal{M}$ and $T \subseteq S$ be a set of target states in $\mathcal{M}$.
We can compute the probability to reach $T$ from $s$:
let $(x_s)_{s \in S} \in [0, 1]$,
\begin{itemize}
	\item if $s$ is not connected to $T$ in the underlying graph of $\mathcal{M}$, then we have $x_s = 0$
	\item else, if $s \in T$, then we have $x_s = 1$
	\item else, for all $s \in S \setminus T$  such that $s$ is connected to $T$ in the underlying graph of $\mathcal{M}$,
		\[
      x_s = \underbrace{\sum_{s' \in S \setminus T} \Delta(s, s') \cdot x_{s'}}_{\text{reach $T$ via $s' \in S \setminus T$}} + \underbrace{\sum_{t \in T} \Delta(s, t)}_{\text{reach $T$ in one transition}}
    \]
\end{itemize}
This defines a system of linear equations.
Let $S_{=0}$ be the subset of states of $S$ that are not connected to $T$ in the underlying graph of $\mathcal{M}$ (i.e., the set of states $s$ from which no path reaching $T$ exists, i.e., for all $\pi = s_0s_1\dots \in Paths(s)$ and for all $k \in \mathbb{N}$, $s_k \not\in T$), $S_{=1} = T$ and $S_{=?} = S \setminus (S_{=0} \cup S_{=1})$.
The solution $(x_s)_{s \in S_{=?}}$ of this linear equations system is unique and $x_s = \mathbb{P}_s(\Diamond T)$ for all $s \in S$.

\subsection{Expected cost-to-target paths in a Markov Chain}\label{app-expMC}
  Let $\mathcal{M} = (S, \Delta, w, AP, L)$ be an MC, $s \in S$ be a state of $\mathcal{M}$ and $T \subseteq$ S be a set of targets states. $\mathbb{E}_s(\Diamond T)$ can be computed through a linear equations system defined as follows:
  %Soient $x_s = \mathbb{E}_s(TS^T)$ %et $S_{=1} = \{s \in S \; | \; \mathbb{P}_s_s(\Diamond T) = 1 \}$
  let $succ(s) = \{ s' \in S \; | \; \Delta(s, s') > 0 \}$ be the set of successors of $s$,
  \[ x_s =
  	\begin{cases}
  	\infty & \quad \text{if } \mathbb{P}_s(\Diamond T) < 1, \\
  	0 & \quad \text{if } s \in T, \text{ and} \\
  	\sum_{s' \in succ(s)} \Delta(s, s') \cdot (w(s, s') + x_{s'}) & \quad \text{else}.
  	\end{cases}
  \]
Let $S_{=?} = \{ s \in S \; | \; \mathbb{P}_s(\Diamond T) = 1 \} \setminus T$. The solution $(x_s)_{s \in S_{=?}}$ of this linear equations system is unique and $x_s = \mathbb{E}_s(\Diamond T)$ for all $s \in S$.

\section{Cost bounded reachability in a Markov chain}\label{app-cbrMC}

Let $\mathcal{M} = (S, \Delta, w, AP, L)$ be an MC. We denote by $\mathbb{P}^\mathcal{M}_s$ the probability measure $\mathbb{P}_s$ such that $s \in S$ on $\mathcal{M}$.
Let $s \in S$ be a state of $\mathcal{M}$, $T \subseteq S$ be a set of target states and $l \in \mathbb{N}$ be a threshold.
We can compute $\mathbb{P}^{\mathcal{M}}_s(\Diamond_{\leq l} T)$ by reduction to the reachability problem on $\mathcal{M}_l = (S_l, \Delta_l)$ to the set of target states $T_l \subseteq S_l$ that we build as follows:
\begin{itemize}
	\item $S_l$ contains all states $(s, v)$ such that $s \in S $ and $v \in \mathbb{N} \cup \{ \bot \}$. We consider that $\bot > l$, with $\bot + v = \bot$ for all $v \in \mathbb{N}$. Intuitively, we record in $v$ the cost of paths while unfolding $\mathcal{M}$. Target states are states of $T_l = \{ (s, v) \in S_l \; | \; s \in T \wedge v \leq l \}$.
	\item $\Delta_l: S_l \times S_l \rightarrow [0,1]$ is the probability transition function given by:\\
	$\forall (s, v), (s', v') \in S_l,$
	\[
		\Delta_l((s, v), (s', v')) =
		\begin{cases}
		\Delta(s, s') & \text{if $v' = v + w(s, s')$ and $v' \leq l$  or} \\
		 & \text{if $v' = \bot$ and $v + w(s, s') > l$} \\
		 0 & \text{else}
		\end{cases}
	\]
\end{itemize}
\textit{Remark}: here, the weight function is ommited in $\mathcal{M}_l$. So, $\mathcal{M}_l$ is unweighted. \\
Resolving the cost bounded reachability by the threshold $l$ from $s$ to $T$ in $\mathcal{M}$ can be done by resolving the reachbility problem from $(s, 0)$ to $T_l$ in $\mathcal{M}_l$, i.e., $\mathbb{P}^\mathcal{M}_s(\Diamond_{\leq l} T) = \mathbb{P}^{\mathcal{M}_l}_{(s, 0)}(\Diamond T_l)$

\section{Linear programs}\label{LP-app}
\subsection{Stochastic reachability problem}\label{app-sr}
Let $\mathcal{M}=(S, A, \Delta, w, AP, L)$ be an MDP and $T \subseteq S$ be a set of target states of $\mathcal{M}$. Let $\alpha \in [0, 1]$ be a probability threshold.  We will build an optimal strategy $\sigma$ for the SR problem. Indeed, we will compute through an LP $\max_{\sigma} \mathbb{P}_s^\sigma (\Diamond T) = \mathbb{P}_s^{\max}(\Diamond T)$ for all $s \in S$. If $\mathbb{P}_s^\sigma(\Diamond T) \geq \alpha$, $\sigma$
is obviously optimal for the
SR problem from $s$ to $T$. Otherwise, no strategy satisfying the SR problem exist. Let $S_{=1}$ be a subset of states such that $T \subseteq S_{=1}\subseteq \{s \in S \; | \; \mathbb{P}^{\max}_s(\Diamond T) = 1$\}
and $(x_s)_{s \in S} \subseteq [0, 1]^{|S|}$
be a vector for the following LP:
\[
	\min \sum_{s \in S} x_s
\]
under the constraints :
\begin{flalign*}
	x_s &= 1 \quad &&\forall s \in S_{=1}, \\
	x_s &= 0 \quad &&\forall s \not\in S_{=1} \text{ such that $s$ is not connected to $T$ in $G^\mathcal{M}$}, \\
	x_s &\geq \sum_{s' \in S} \Delta(s, \alpha, s') \cdot x_{s'}
	\quad &&\forall s \not \in S_{=1} \text{ such
		that $s$ is connected to $T$ in $G^\mathcal{M}$} \text{ and } \forall \alpha \in A(s), \text{ and} \\
	0 &\leq x_s \leq 1 && \forall s \in S
\end{flalign*}
\textit{Remark}: we denote by $G^\mathcal{M}$ the underlying graph of $\mathcal{M}$. \\

The optimal solution $(v_s)_{s \in S}$ of this LP is unique and gives the following result :
\[
	v_s = \mathbb{P}_s^{\max}(\Diamond T) \quad \forall s \in S
\]
From this result, we can build an optimal memoryless strategy $\sigma$ such that
$\mathbb{P}^\sigma_s(\Diamond T) = \mathbb{P}^{\max}_s(\Diamond T)$.
To do that, for each state $s$, we build $A^{\max}(s)$, the set of
actions $\alpha \in A(s)$ such that
$
	v_s = \sum_{s' \in S} \Delta(s, \alpha, s') \cdot v_{s'}
$. Thus, since we have $v_s = \mathbb{P}^{\max}_s(\Diamond T)$, actions of $A^{\max}(s)$
maximise the probability of reaching $T$ from $s$.
Building a strategy that would arbitrarily choose a state of
$A^{\max}(s)$ is not sufficient. Indeed, let assume that we have a state $s$ in the MDP
such that $A^{\max}(s) = \{\alpha, \beta\}$, where $\Delta(s, \beta, t) = 1$
for a certain $t \in T$ and $\Delta(s, \alpha, s) = 1$, we obviously have
that choosing $\alpha$ doesn't allow to reach $T$ passing by $s$.
\\

A selection of actions ensuring
the reachability to $T$ in the
MC induced by $\sigma$ is required.
Let $\mathcal{M}^{\max}$ be the MDP that corresponds to $\mathcal{M}$
where actions $\beta \in A(s) \setminus A^{\max}(s)$ are deleted from $A(s)$,
for all $s$ connected to $T$.
By definition, $\mathbb{P}^{\max}_s(\Diamond T)$ is not affected by this simplification of
$\mathcal{M}$. \\

For all $s$ such that $s$ is connected to $T$ in the underlying graph of
$\mathcal{M}^{\max}$, we denote by $||s||$ the length of the \textit{shortest path} (in terms of steps) of $s$ to any state of $T$ in the underlying graph of
$\mathcal{M^{\max}}$. Intuitively, computing $||s||$ allow to avoid that $\sigma$ chooses
actions that prevent $s$ of reaching $T$.
\begin{itemize}
	\renewcommand{\labelitemi}{\tiny$\bullet$}
	\item $||s|| = 0$ iff $s \in T$.
	\item Let $n \in \mathbb{N}_0$. By induction on $n$, we define
		$\sigma(s)$ for each $s$ connected to $T$ in the underlying graph of
		$\mathcal{M^{\max}}$ and such that $||s|| = n$.
		The strategy chooses an action $\sigma(s) \in A^{\max}(s)$ such that there exists a successor $s' \in Succ(s, \sigma(s))$, with $s'$ connected to $T$ in the underlying graph of
		$\mathcal{M}^{\max}$ and $||s'|| = n - 1$. An action $\sigma(s) \in A(s)$ is chosen
		arbitrarely for states $s$ that are not connected to $T$ in the underlying graph of $\mathcal{M}$.
\end{itemize}
We build $\sigma$ this way: let $s \in S$ be a state of $\mathcal{M}$ and $\mathbb{A}(s) = \{\alpha \in A^{\max}(s) \; | \; \exists s' \in Succ(s,
	\alpha), \, ||s'|| = ||s|| - 1 \}$,
\[
%\sigma(s) = \arg \max_{\alpha \in \mathbb{A}(s)} \sum_{s' \in Succ(s, \alpha)} \Delta(s,
%\alpha, s') \cdot v_{s'}
	\sigma(s) = \alpha \;\; \text{such that } \alpha \in \mathbb{A}(s)
\]

Furthermore, we can optimise computations to get the optimal solution of this LP by choosing the largest subset $S_{=1}$, i.e., $S_{=1}=\{s\in S \; | \; \mathbb{P}^{\max}_s(\Diamond T) = 1\}$, with the following algorithm:

\begin{algorithm}[H]
\caption{Build the largest subset $S_{=1}$}
\label{prMax1}
\begin{algorithmic}[1]
\REQUIRE{
		$\mathcal{M} = (S, A, \Delta, w, AP, L)$, a finite MDP, and
		$T \subseteq S$, a subset of target states.
	}
\ENSURE{
	The set of states $s$ of $\mathcal{M}$ for which
		$\mathbb{P}_{s}^{\max} (\Diamond T)= 1$.
}
\STATE $U \gets \{ s \in S \; | \; s \text{ is not connected to } T \text{ in } G^\mathcal{M}\}$
\COMMENT{$U$ is the set of ``bad states''}
\WHILE{$U \neq \emptyset$}
	\STATE $R \gets U$
	\WHILE{$R \neq \emptyset$}
		\STATE Let $u \in R$
		\COMMENT{let $u$ be a bad state}
		\STATE $R \gets R \setminus \{u \}$
		\COMMENT{mark $u$ as visited}
		\FORALL{$(s, \alpha) \in Pred(u)$ such that $s \not\in U \cup T$}
			\STATE remove $\alpha$ from $A(s)$
			\COMMENT{remove all ingoing edges of $u$}
			\IF{$A(s) = \emptyset$}
				\STATE $R \gets R \cup \{s\}$
				\COMMENT{\scriptsize for any enabled action, $s$ is always connected to a bad state}
				\STATE $U \gets U \cup \{s\}$
				\COMMENT{thus, $s$ is marked as bad state}
			\ENDIF
		\ENDFOR
		\STATE remove $u$ and its outgoing edges in $\mathcal{M}$
	\ENDWHILE
	\STATE $U \gets \{ s \in S \setminus U \; | \; s \text{ is not connected to } T \text{ in } G^\mathcal{M} \}$
	\COMMENT{\scriptsize update the set of bad states}
\ENDWHILE
\RETURN the remaining states
\end{algorithmic}
\end{algorithm}

This algorithm is exact and polynomial in the size of $\mathcal{M}$ (cf. \cite{PMC}).

\subsection{Stochastic shortest path expectation problem}\label{app-sspe}
Let $\mathcal{M}=(S, A, \Delta, w, AP, L)$ be an MDP and $T \subseteq S$ be a set
of target states of $\mathcal{M}$. We will build an optimal strategy $\sigma$ that will minimise the expected cost of paths to reach $T$
from all states $s \in S$ of $\mathcal{M}$.
So, we will first compute $\min_{\sigma}\mathbb{E}^\sigma_s(\Diamond T) = \mathbb{E}^{\min}_s(\Diamond T)$, for all $s \in S$.
Let $l \in \mathbb{N}$ be a length threshold.
 If $\mathbb{E}_s^\sigma(\Diamond T) \geq l$, $\sigma$ satisfies the
\SSPE{} problem for the state $s$. Otherwise, no strategy satisfying the \SSPE{} problem exist.
Let $S_{=1} = \{ s \in S \; | \; \mathbb{P}^{\max}_s(\Diamond T) = 1 \}$ be the set of states that reach $T$ with a maximum probability one and $(x_s)_{s \in S}$ be a vector for the following LP:
		\[ \max \sum_{s \in S_{=1}} x_s \]
		under the constraints \\
	%	\begin{equation*}
	%  \renewcommand{\arraystretch}{1.3}
	%  \begin{array}{ll}
	%		x_s = \infty \quad
	%	\end{array}
	%\end{equation*}
	\begin{flalign*}
		x_s &= 0 && \forall s \in T, \\
		x_s &= \infty && \text{$\forall s \in S$ such that $\mathbb{P}^{\max}_s(\Diamond T) < 1$}, \text{ and} \\
		x_s &\leq w(\alpha) + \sum_{s' \in Succ(s, \alpha) \setminus T} \Delta(s, \alpha, s')
			\cdot x_{s'} && \forall \alpha \in A(s) \text{ and } \forall s \in S \setminus T \text{ such that } \mathbb{P}^{\max}_s(\Diamond T) = 1.
	\end{flalign*}
The optimal solution $(v_s)_{s \in S}$ of this LP is unique and gives the following result:
\[
	v_s = \mathbb{E}^{\min}_s(\Diamond T) \quad \forall s \in S
\]
We can now build an optimal pure memoryless strategy $\sigma$ that minimises the expected cost of paths of $\mathcal{M}$ to reach $T$ :
\[
	\sigma(s) = \arg \min_{\alpha \in A(s)} ( w(\alpha) +
		\sum_{s' \in Succ(s, \alpha) \setminus T} \Delta(s, \alpha, s') \cdot v_{s'} ) \]

\addtocounter{chapter}{1}
\setcounter{section}{0}
\section{Prism to Jani format using Storm}\label{prism2jani}
Let $\mathcal{M}$ be the MDP defined as follows in the Prism language:
\lstinputlisting[language={Prism},
    rulesepcolor=\color{black}, rulecolor=\color{black}, breaklines=true,
    breakatwhitespace=true, firstnumber=1, firstline=1, lastline=25]{resources/simple_mdp.prism}
$\mathcal{M}$ is actually the MDP of the figure \ref{prism-simple}.
Storm allows to convert this model to Jani with the following command :
{\scriptsize
\begin{verbatim}
storm-pars --prism2jani --prism simple_mdp.prism --exportJani:jani-output simple_mdp.jani
\end{verbatim}
}
The Jani ouput is the following :
\lstinputlisting[language={json}]
    {resources/simple_mdp.jani}

\section{Bellman equation system for min. expected cost-to-target} \label{bellman2}
  Let $\mathcal{M}$ be a finite MDP with state space $S$ and with a probability transition function $\Delta$, $s \in S$ be a state of $\mathcal{M}$ and $T \subseteq S$ be a subset of target states. The vector $(x_s)_{s \in S}$ with $x_s = \mathbb{E}_s^{\min}(\TS^T)$ yields the unique solution of the following equation system: let the subset $S_{=1} = \{s \in S \; | \; \mathbb{P}^{\max}_s(\Diamond T) = 1 \}$,
  \begin{itemize}
    \item if $s \in T$, then $x_s=0$,
    \item else if $s \not \in S_{=1}$, then $x_s=\infty$,
    \item else,
    \[ x_s = \min_{\alpha \in A(s)} \big( w(\alpha) + \sum_{s' \in Succ(s, \alpha)} \Delta(s, \alpha, s') \cdot x_{s'} \big). \]
  \end{itemize}
The linear program defined in Appendix \ref{app-sspe} is actually derived from this equation system.
In the literature, this equation is often presented with a \textit{discount rate} multiplied with each term of the sum of the equation
(i.e., $x_s = \min_{\alpha \in A(s)} ( w(\alpha) + \sum_{s' \in Succ(s, \alpha)} \Delta(s, \alpha, s') \cdot \gamma \cdot x_{s'} )$, with $\gamma \in \,]0, 1[ \, \cap \,\mathbb{Q}$).
This actually refers to another cost function replacing the truncated sum, i.e., the discounted sum function, expressing that short-term costs are most important that long-term ones.
